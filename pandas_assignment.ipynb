{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a89dcb8-cc12-42c6-90b0-365bf7645a18",
   "metadata": {},
   "source": [
    "**Assignment 2 - Pandas**\n",
    "\n",
    "**1.\tImport the attached Netflix csv file in Jupyter notebook and perform following operations using Pandas:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eae8c3b2-18f3-4e17-a576-705a9c9ccde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('C:/Users/under/Downloads/netflix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "44948a9d-ad1e-41de-bccd-0c0d5bc68e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Kirsten Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>September 25, 2021</td>\n",
       "      <td>2020</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Documentaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Julien Leclercq</td>\n",
       "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Jailbirds New Orleans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Docuseries, Reality TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Kota Factory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...</td>\n",
       "      <td>India</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, Romantic TV Shows, TV ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>s8803</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Zodiac</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>Mark Ruffalo, Jake Gyllenhaal, Robert Downey J...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 20, 2019</td>\n",
       "      <td>2007</td>\n",
       "      <td>R</td>\n",
       "      <td>158 min</td>\n",
       "      <td>Cult Movies, Dramas, Thrillers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>s8804</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Zombie Dumb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 1, 2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-Y7</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>Kids' TV, Korean TV Shows, TV Comedies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>s8805</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Zombieland</td>\n",
       "      <td>Ruben Fleischer</td>\n",
       "      <td>Jesse Eisenberg, Woody Harrelson, Emma Stone, ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 1, 2019</td>\n",
       "      <td>2009</td>\n",
       "      <td>R</td>\n",
       "      <td>88 min</td>\n",
       "      <td>Comedies, Horror Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>s8806</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Zoom</td>\n",
       "      <td>Peter Hewitt</td>\n",
       "      <td>Tim Allen, Courteney Cox, Chevy Chase, Kate Ma...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 11, 2020</td>\n",
       "      <td>2006</td>\n",
       "      <td>PG</td>\n",
       "      <td>88 min</td>\n",
       "      <td>Children &amp; Family Movies, Comedies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>s8807</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Zubaan</td>\n",
       "      <td>Mozez Singh</td>\n",
       "      <td>Vicky Kaushal, Sarah-Jane Dias, Raaghav Chanan...</td>\n",
       "      <td>India</td>\n",
       "      <td>March 2, 2019</td>\n",
       "      <td>2015</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>111 min</td>\n",
       "      <td>Dramas, International Movies, Music &amp; Musicals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8780 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     show_id     type                  title         director  \\\n",
       "0         s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
       "1         s2  TV Show          Blood & Water              NaN   \n",
       "2         s3  TV Show              Ganglands  Julien Leclercq   \n",
       "3         s4  TV Show  Jailbirds New Orleans              NaN   \n",
       "4         s5  TV Show           Kota Factory              NaN   \n",
       "...      ...      ...                    ...              ...   \n",
       "8775   s8803    Movie                 Zodiac    David Fincher   \n",
       "8776   s8804  TV Show            Zombie Dumb              NaN   \n",
       "8777   s8805    Movie             Zombieland  Ruben Fleischer   \n",
       "8778   s8806    Movie                   Zoom     Peter Hewitt   \n",
       "8779   s8807    Movie                 Zubaan      Mozez Singh   \n",
       "\n",
       "                                                   cast        country  \\\n",
       "0                                                   NaN  United States   \n",
       "1     Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
       "2     Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
       "3                                                   NaN            NaN   \n",
       "4     Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
       "...                                                 ...            ...   \n",
       "8775  Mark Ruffalo, Jake Gyllenhaal, Robert Downey J...  United States   \n",
       "8776                                                NaN            NaN   \n",
       "8777  Jesse Eisenberg, Woody Harrelson, Emma Stone, ...  United States   \n",
       "8778  Tim Allen, Courteney Cox, Chevy Chase, Kate Ma...  United States   \n",
       "8779  Vicky Kaushal, Sarah-Jane Dias, Raaghav Chanan...          India   \n",
       "\n",
       "              date_added  release_year rating   duration  \\\n",
       "0     September 25, 2021          2020  PG-13     90 min   \n",
       "1     September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "2     September 24, 2021          2021  TV-MA   1 Season   \n",
       "3     September 24, 2021          2021  TV-MA   1 Season   \n",
       "4     September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "...                  ...           ...    ...        ...   \n",
       "8775   November 20, 2019          2007      R    158 min   \n",
       "8776        July 1, 2019          2018  TV-Y7  2 Seasons   \n",
       "8777    November 1, 2019          2009      R     88 min   \n",
       "8778    January 11, 2020          2006     PG     88 min   \n",
       "8779       March 2, 2019          2015  TV-14    111 min   \n",
       "\n",
       "                                              listed_in  \n",
       "0                                         Documentaries  \n",
       "1       International TV Shows, TV Dramas, TV Mysteries  \n",
       "2     Crime TV Shows, International TV Shows, TV Act...  \n",
       "3                                Docuseries, Reality TV  \n",
       "4     International TV Shows, Romantic TV Shows, TV ...  \n",
       "...                                                 ...  \n",
       "8775                     Cult Movies, Dramas, Thrillers  \n",
       "8776             Kids' TV, Korean TV Shows, TV Comedies  \n",
       "8777                            Comedies, Horror Movies  \n",
       "8778                 Children & Family Movies, Comedies  \n",
       "8779     Dramas, International Movies, Music & Musicals  \n",
       "\n",
       "[8780 rows x 11 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07ee45-45b7-414a-b1df-de23ce5bb78d",
   "metadata": {},
   "source": [
    "**a)Print the first 5 rows and last 5 rows of the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "009d4753-9023-4426-b9b2-4800610ee5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  show_id     type                  title         director  \\\n",
      "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
      "1      s2  TV Show          Blood & Water              NaN   \n",
      "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
      "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
      "4      s5  TV Show           Kota Factory              NaN   \n",
      "\n",
      "                                                cast        country  \\\n",
      "0                                                NaN  United States   \n",
      "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
      "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
      "3                                                NaN            NaN   \n",
      "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
      "\n",
      "           date_added  release_year rating   duration  \\\n",
      "0  September 25, 2021          2020  PG-13     90 min   \n",
      "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "2  September 24, 2021          2021  TV-MA   1 Season   \n",
      "3  September 24, 2021          2021  TV-MA   1 Season   \n",
      "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "\n",
      "                                           listed_in  \n",
      "0                                      Documentaries  \n",
      "1    International TV Shows, TV Dramas, TV Mysteries  \n",
      "2  Crime TV Shows, International TV Shows, TV Act...  \n",
      "3                             Docuseries, Reality TV  \n",
      "4  International TV Shows, Romantic TV Shows, TV ...  \n",
      "     show_id     type        title         director  \\\n",
      "8775   s8803    Movie       Zodiac    David Fincher   \n",
      "8776   s8804  TV Show  Zombie Dumb              NaN   \n",
      "8777   s8805    Movie   Zombieland  Ruben Fleischer   \n",
      "8778   s8806    Movie         Zoom     Peter Hewitt   \n",
      "8779   s8807    Movie       Zubaan      Mozez Singh   \n",
      "\n",
      "                                                   cast        country  \\\n",
      "8775  Mark Ruffalo, Jake Gyllenhaal, Robert Downey J...  United States   \n",
      "8776                                                NaN            NaN   \n",
      "8777  Jesse Eisenberg, Woody Harrelson, Emma Stone, ...  United States   \n",
      "8778  Tim Allen, Courteney Cox, Chevy Chase, Kate Ma...  United States   \n",
      "8779  Vicky Kaushal, Sarah-Jane Dias, Raaghav Chanan...          India   \n",
      "\n",
      "             date_added  release_year rating   duration  \\\n",
      "8775  November 20, 2019          2007      R    158 min   \n",
      "8776       July 1, 2019          2018  TV-Y7  2 Seasons   \n",
      "8777   November 1, 2019          2009      R     88 min   \n",
      "8778   January 11, 2020          2006     PG     88 min   \n",
      "8779      March 2, 2019          2015  TV-14    111 min   \n",
      "\n",
      "                                           listed_in  \n",
      "8775                  Cult Movies, Dramas, Thrillers  \n",
      "8776          Kids' TV, Korean TV Shows, TV Comedies  \n",
      "8777                         Comedies, Horror Movies  \n",
      "8778              Children & Family Movies, Comedies  \n",
      "8779  Dramas, International Movies, Music & Musicals  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09005ce1-4997-48a2-b8b0-3d80a365ecb1",
   "metadata": {},
   "source": [
    "**b)\tCheck how many rows and columns are there using Pandas function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e3be671f-9e90-42f2-b700-bffcc71a864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8780\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95f200-bd4f-43ed-98f4-86f878419eb9",
   "metadata": {},
   "source": [
    "**c) Print all the column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6adca7c0-c7af-494e-963d-705d34f84f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
      "       'release_year', 'rating', 'duration', 'listed_in'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461bd9ac-ff22-4c2c-8bf8-a5d2692078b2",
   "metadata": {},
   "source": [
    "**d) Calculate the descriptive statistics of all the variables (integer/float/object, etc.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c20c96c1-169b-4897-9ce2-d9e5fe87f910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       show_id   type                 title       director  \\\n",
      "count     8780   8780                  8780           6150   \n",
      "unique    8780      2                  8780           4516   \n",
      "top         s1  Movie  Dick Johnson Is Dead  Rajiv Chilaka   \n",
      "freq         1   6110                     1             19   \n",
      "mean       NaN    NaN                   NaN            NaN   \n",
      "std        NaN    NaN                   NaN            NaN   \n",
      "min        NaN    NaN                   NaN            NaN   \n",
      "25%        NaN    NaN                   NaN            NaN   \n",
      "50%        NaN    NaN                   NaN            NaN   \n",
      "75%        NaN    NaN                   NaN            NaN   \n",
      "max        NaN    NaN                   NaN            NaN   \n",
      "\n",
      "                      cast        country       date_added  release_year  \\\n",
      "count                 7956           7952             8770   8780.000000   \n",
      "unique                7671            745             1765           NaN   \n",
      "top     David Attenborough  United States  January 1, 2020           NaN   \n",
      "freq                    19           2809              108           NaN   \n",
      "mean                   NaN            NaN              NaN   2014.178474   \n",
      "std                    NaN            NaN              NaN      8.827938   \n",
      "min                    NaN            NaN              NaN   1925.000000   \n",
      "25%                    NaN            NaN              NaN   2013.000000   \n",
      "50%                    NaN            NaN              NaN   2017.000000   \n",
      "75%                    NaN            NaN              NaN   2019.000000   \n",
      "max                    NaN            NaN              NaN   2021.000000   \n",
      "\n",
      "       rating  duration                     listed_in  \n",
      "count    8776      8780                          8780  \n",
      "unique     14       220                           514  \n",
      "top     TV-MA  1 Season  Dramas, International Movies  \n",
      "freq     3198      1788                           361  \n",
      "mean      NaN       NaN                           NaN  \n",
      "std       NaN       NaN                           NaN  \n",
      "min       NaN       NaN                           NaN  \n",
      "25%       NaN       NaN                           NaN  \n",
      "50%       NaN       NaN                           NaN  \n",
      "75%       NaN       NaN                           NaN  \n",
      "max       NaN       NaN                           NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f6e1a-c577-4283-9452-6058304d39a4",
   "metadata": {},
   "source": [
    "**e) Check the number of unique values for each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "87c7f448-fc5e-4d99-8c84-1450cf1d2d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id         8780\n",
      "type               2\n",
      "title           8780\n",
      "director        4516\n",
      "cast            7671\n",
      "country          745\n",
      "date_added      1765\n",
      "release_year      74\n",
      "rating            14\n",
      "duration         220\n",
      "listed_in        514\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values = df.nunique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df021b-9872-42a0-a23e-1d8aa3d4c304",
   "metadata": {},
   "source": [
    "**f) Check the percentage of missing values for each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "28a25ac4-2981-47cb-9214-63db195d5a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id          0.000000\n",
      "type             0.000000\n",
      "title            0.000000\n",
      "director        29.954442\n",
      "cast             9.384966\n",
      "country          9.430524\n",
      "date_added       0.113895\n",
      "release_year     0.000000\n",
      "rating           0.045558\n",
      "duration         0.000000\n",
      "listed_in        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f46b6-e2fb-4b80-acb0-50a53a7d99f6",
   "metadata": {},
   "source": [
    "**g) Delete all the rows where the 'Director' column has missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "60c097cd-da2b-4219-bc81-646d75c0060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna(subset=['director'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "62724451-d2be-4432-8dcd-65875dd62f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 6150\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df1.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a7bd8-860c-4dc6-951a-d1651e10d5f8",
   "metadata": {},
   "source": [
    "**h)Print all the records where country has Germany value (including West Germany).If any other country is there along with Germany, then that row should also come in output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9885e61e-ea37-4147-ad22-411b75ca42ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     show_id   type                                title  \\\n",
      "7         s8  Movie                              Sankofa   \n",
      "12       s13  Movie                         Je Suis Karl   \n",
      "129     s130  Movie                   An Unfinished Life   \n",
      "142     s143  Movie                      Freedom Writers   \n",
      "172     s173  Movie                       School of Rock   \n",
      "...      ...    ...                                  ...   \n",
      "8590   s8618  Movie                                Trash   \n",
      "8634   s8662  Movie                      Unfinished Song   \n",
      "8641   s8669  Movie                       V for Vendetta   \n",
      "8702   s8730  Movie                   Where the Money Is   \n",
      "8718   s8746  Movie  Willy Wonka & the Chocolate Factory   \n",
      "\n",
      "                  director                                               cast  \\\n",
      "7             Haile Gerima  Kofi Ghanaba, Oyafunmike Ogunlano, Alexandra D...   \n",
      "12     Christian Schwochow  Luna Wedler, Jannis Niewöhner, Milan Peschel, ...   \n",
      "129        Lasse Hallström  Robert Redford, Jennifer Lopez, Morgan Freeman...   \n",
      "142    Richard LaGravenese  Hilary Swank, Patrick Dempsey, Scott Glenn, Im...   \n",
      "172      Richard Linklater  Jack Black, Joan Cusack, Mike White, Sarah Sil...   \n",
      "...                    ...                                                ...   \n",
      "8590        Stephen Daldry  Wagner Moura, Martin Sheen, Rooney Mara, Selto...   \n",
      "8634  Paul Andrew Williams  Terence Stamp, Gemma Arterton, Christopher Ecc...   \n",
      "8641        James McTeigue  Natalie Portman, Hugo Weaving, Stephen Rea, St...   \n",
      "8702       Marek Kanievska  Paul Newman, Linda Fiorentino, Dermot Mulroney...   \n",
      "8718            Mel Stuart  Gene Wilder, Jack Albertson, Peter Ostrum, Roy...   \n",
      "\n",
      "                                                country          date_added  \\\n",
      "7     United States, Ghana, Burkina Faso, United Kin...  September 24, 2021   \n",
      "12                              Germany, Czech Republic  September 23, 2021   \n",
      "129                              Germany, United States   September 1, 2021   \n",
      "142                              Germany, United States   September 1, 2021   \n",
      "172                              United States, Germany   September 1, 2021   \n",
      "...                                                 ...                 ...   \n",
      "8590                    United Kingdom, Brazil, Germany     January 1, 2019   \n",
      "8634                            United Kingdom, Germany       July 22, 2019   \n",
      "8641             United States, United Kingdom, Germany     October 1, 2018   \n",
      "8702     Germany, United States, United Kingdom, Canada    January 15, 2020   \n",
      "8718          United States, East Germany, West Germany     January 1, 2020   \n",
      "\n",
      "      release_year rating duration  \\\n",
      "7             1993  TV-MA  125 min   \n",
      "12            2021  TV-MA  127 min   \n",
      "129           2005  PG-13  108 min   \n",
      "142           2007  PG-13  124 min   \n",
      "172           2003  PG-13  110 min   \n",
      "...            ...    ...      ...   \n",
      "8590          2014      R  114 min   \n",
      "8634          2012  PG-13   94 min   \n",
      "8641          2005      R  132 min   \n",
      "8702          2000  PG-13   89 min   \n",
      "8718          1971      G  100 min   \n",
      "\n",
      "                                              listed_in  \n",
      "7      Dramas, Independent Movies, International Movies  \n",
      "12                         Dramas, International Movies  \n",
      "129                                              Dramas  \n",
      "142                                              Dramas  \n",
      "172                          Comedies, Music & Musicals  \n",
      "...                                                 ...  \n",
      "8590              Dramas, Independent Movies, Thrillers  \n",
      "8634               Comedies, Dramas, Independent Movies  \n",
      "8641       Action & Adventure, Dramas, Sci-Fi & Fantasy  \n",
      "8702               Action & Adventure, Comedies, Dramas  \n",
      "8718  Children & Family Movies, Classic Movies, Come...  \n",
      "\n",
      "[183 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "germany_records = df1[df1['country'].str.contains('Germany', case=False, na=False)]\n",
    "print(germany_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f43cfc-0498-445a-bd21-58c4fe2187a9",
   "metadata": {},
   "source": [
    "**i) Expand the \"Duration\" column into 2 separate columns – one with numeric value and the other with a string (e.g., \"3 seasons\" should be split into 3 in one column and \"seasons\" in another).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4f55c449-42b5-4d9d-aeac-d48db7a7d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  duration_numeric duration_unit\n",
      "0    90 min                90           min\n",
      "2  1 Season                 1        Season\n",
      "5  1 Season                 1        Season\n",
      "6    91 min                91           min\n",
      "7   125 min               125           min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\776181350.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df1[['duration_numeric', 'duration_unit']] = df1['duration'].str.extract('(\\d+)\\s*(\\D+)')\n",
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\776181350.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[['duration_numeric', 'duration_unit']] = df1['duration'].str.extract('(\\d+)\\s*(\\D+)')\n",
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\776181350.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[['duration_numeric', 'duration_unit']] = df1['duration'].str.extract('(\\d+)\\s*(\\D+)')\n",
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\776181350.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['duration_numeric'] = pd.to_numeric(df1['duration_numeric'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "df1[['duration_numeric', 'duration_unit']] = df1['duration'].str.extract('(\\d+)\\s*(\\D+)')\n",
    "df1['duration_numeric'] = pd.to_numeric(df1['duration_numeric'], errors='coerce')\n",
    "print(df1[['duration', 'duration_numeric', 'duration_unit']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37140f-99d9-46d2-9626-0bb760c177c0",
   "metadata": {},
   "source": [
    "**j)\tSplit Date added into 3 separate columns having date value in 1st column, month value in 2nd column and year value in 3rd.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "372a406a-60de-44fa-9b11-80d113f3ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Date  Month    Year\n",
      "0  25.0    9.0  2021.0\n",
      "2  24.0    9.0  2021.0\n",
      "5  24.0    9.0  2021.0\n",
      "6  24.0    9.0  2021.0\n",
      "7  24.0    9.0  2021.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\75427579.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Date'] = df['date_added'].dt.day\n",
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\75427579.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Month'] = df['date_added'].dt.month\n",
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\75427579.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Year'] = df['date_added'].dt.year\n"
     ]
    }
   ],
   "source": [
    "df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n",
    "\n",
    "# Create separate columns for day, month, and year\n",
    "df1['Date'] = df['date_added'].dt.day\n",
    "df1['Month'] = df['date_added'].dt.month\n",
    "df1['Year'] = df['date_added'].dt.year\n",
    "print(df1[['Date', 'Month', 'Year']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef0a83-dfbf-418f-9f65-6b9fbee6db45",
   "metadata": {},
   "source": [
    "**k)\tPrint the number of TV shows/Movies released in each year.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c787330c-cc60-421c-b181-e10856c24f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2008.0       1\n",
      "2009.0       2\n",
      "2010.0       1\n",
      "2011.0      13\n",
      "2012.0       3\n",
      "2013.0       7\n",
      "2014.0      18\n",
      "2015.0      57\n",
      "2016.0     239\n",
      "2017.0     847\n",
      "2018.0    1209\n",
      "2019.0    1410\n",
      "2020.0    1312\n",
      "2021.0    1026\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "release_counts = df1.groupby('Year').size()\n",
    "print(release_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b960a-03fd-485a-81dd-b733e5eff6ce",
   "metadata": {},
   "source": [
    "**l)\tRename the column title with movie_title.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "73753bae-9b7b-4117-a66f-0ca3888ce30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  show_id     type                       movie_title\n",
      "0      s1    Movie              Dick Johnson Is Dead\n",
      "2      s3  TV Show                         Ganglands\n",
      "5      s6  TV Show                     Midnight Mass\n",
      "6      s7    Movie  My Little Pony: A New Generation\n",
      "7      s8    Movie                           Sankofa\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.rename(columns={'title': 'movie_title'})\n",
    "print(df1[['show_id', 'type', 'movie_title']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2f2eb-48da-4e8e-bb40-dd90632a1eb2",
   "metadata": {},
   "source": [
    "**m)\tSplit Listed_in column into 3 different columns with col name (Genre1, Genre2, Genre3). Split the column based on comma.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "934794d7-ba78-4e4b-b401-05514e8d729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                        Documentaries\n",
      "2    Crime TV Shows, International TV Shows, TV Act...\n",
      "5                   TV Dramas, TV Horror, TV Mysteries\n",
      "6                             Children & Family Movies\n",
      "7     Dramas, Independent Movies, International Movies\n",
      "Name: listed_in, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df1['listed_in'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "958efa72-734a-4b44-b300-1d9276bc8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['Genre1', 'Genre2', 'Genre3']] = df1['listed_in'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c3730b11-6bab-4aed-a941-2df5673aa85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Genre1                   Genre2                  Genre3\n",
      "0             Documentaries                     None                    None\n",
      "2            Crime TV Shows   International TV Shows   TV Action & Adventure\n",
      "5                 TV Dramas                TV Horror            TV Mysteries\n",
      "6  Children & Family Movies                     None                    None\n",
      "7                    Dramas       Independent Movies    International Movies\n"
     ]
    }
   ],
   "source": [
    "print(df1[['Genre1', 'Genre2', 'Genre3']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3cd8ec-3ff5-441e-b365-1622efb0ae19",
   "metadata": {},
   "source": [
    "**2.\tImport both the attached files (student.csv and marks.csv) in Jupyter notebook and perform following operations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2df54251-1be0-496a-a5ac-f796e565ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df=pd.read_csv('C:/Users/under/Downloads/student.csv')\n",
    "marks_df=pd.read_csv('C:/Users/under/Downloads/marks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd502aa5-447a-4365-9501-d0214a912a02",
   "metadata": {},
   "source": [
    "**a)\tCombine both the dataframes into single dataframe which will have all the records from both the tables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "67899268-60ea-46c3-aeab-4403301e2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(student_df, marks_df, on='Student_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "82aea5ac-8e0c-4f68-bff9-3a923eff2857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Employed</th>\n",
       "      <th>Mark</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>1st Class</td>\n",
       "      <td>yes</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>2nd Class</td>\n",
       "      <td>no</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>1st Class</td>\n",
       "      <td>no</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>2nd Class</td>\n",
       "      <td>no</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>1st Class</td>\n",
       "      <td>no</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Kochi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>228</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>1st Class</td>\n",
       "      <td>no</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>2nd Class</td>\n",
       "      <td>no</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>230</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>3rd Class</td>\n",
       "      <td>yes</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>231</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>1st Class</td>\n",
       "      <td>yes</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>232</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>3rd Class</td>\n",
       "      <td>yes</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Student_id  Age  Gender      Grade Employed  Mark     City\n",
       "0             1   19    Male  1st Class      yes  95.0  Chennai\n",
       "1             2   20  Female  2nd Class       no  70.0    Delhi\n",
       "2             3   18    Male  1st Class       no  98.0   Mumbai\n",
       "3             4   21  Female  2nd Class       no  75.0     Pune\n",
       "4             5   19    Male  1st Class       no  89.0    Kochi\n",
       "..          ...  ...     ...        ...      ...   ...      ...\n",
       "227         228   21  Female  1st Class       no  99.0     Pune\n",
       "228         229   20    Male  2nd Class       no  70.0  Chennai\n",
       "229         230   20    Male  3rd Class      yes  55.0    Delhi\n",
       "230         231   19  Female  1st Class      yes  97.0   Mumbai\n",
       "231         232   20    Male  3rd Class      yes  59.0     Pune\n",
       "\n",
       "[232 rows x 7 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2904d4f-81b5-4a01-acbf-df67b9c010ff",
   "metadata": {},
   "source": [
    "**b)\tPrint the maximum and minimum marks Gender wise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "958a539d-b777-4a52-adaa-448560bee887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          max   min\n",
      "Gender             \n",
      "Female   99.0  40.0\n",
      "Male    100.0  40.0\n"
     ]
    }
   ],
   "source": [
    "gender_marks = combined_df.groupby('Gender')['Mark'].agg(['max', 'min'])\n",
    "print(gender_marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac722c5-8563-4fd9-8e37-183ac0e68d93",
   "metadata": {},
   "source": [
    "**c)\tPrint all the students IDs and their marks who have scored more than the average marks of the class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "050564b6-ed3f-48a9-8c07-41b054ec8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Student_id  Mark\n",
      "0             1  95.0\n",
      "2             3  98.0\n",
      "3             4  75.0\n",
      "4             5  89.0\n",
      "11           12  90.0\n",
      "..          ...   ...\n",
      "221         222  74.0\n",
      "222         223  79.0\n",
      "224         225  72.0\n",
      "227         228  99.0\n",
      "230         231  97.0\n",
      "\n",
      "[137 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "average_marks = combined_df['Mark'].mean()\n",
    "above_average = combined_df[combined_df['Mark'] > average_marks][['Student_id', 'Mark']]\n",
    "print(above_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76518e4-b5d2-47b8-bf6c-be5dfa0bc9ab",
   "metadata": {},
   "source": [
    "**d)\tPrint the dataframe who are Males and are Employed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f4668a90-7e35-476e-b115-afeabbf602bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Student_id  Age Gender      Grade Employed  Mark     City\n",
      "0             1   19   Male  1st Class      yes  95.0  Chennai\n",
      "5             6   20   Male  2nd Class      yes  69.0  Gwalior\n",
      "7             8   21   Male  3rd Class      yes  54.0  Chennai\n",
      "12           13   19   Male  1st Class      yes  92.0  Gwalior\n",
      "14           15   19   Male  1st Class      yes  97.0     Pune\n",
      "16           17   20   Male  2nd Class      yes  68.0  Gwalior\n",
      "18           19   21   Male  2nd Class      yes  72.0  Chennai\n",
      "29           30   19   Male  1st Class      yes  81.0  Chennai\n",
      "34           35   20   Male  2nd Class      yes  79.0  Gwalior\n",
      "36           37   21   Male  3rd Class      yes  53.0     Pune\n",
      "41           42   19   Male  1st Class      yes  86.0    Delhi\n",
      "43           44   19   Male  1st Class      yes  95.0     Pune\n",
      "45           46   20   Male  2nd Class      yes  79.0    Delhi\n",
      "47           48   21   Male  2nd Class      yes  67.0     Pune\n",
      "58           59   19   Male  1st Class      yes  89.0     Pune\n",
      "63           64   20   Male  2nd Class      yes  78.0    Delhi\n",
      "65           66   21   Male  3rd Class      yes  59.0     Pune\n",
      "70           71   19   Male  1st Class      yes  85.0    Kochi\n",
      "72           73   19   Male  1st Class      yes  89.0   Bhopal\n",
      "74           75   20   Male  2nd Class      yes  79.0    Delhi\n",
      "76           77   21   Male  2nd Class      yes  77.0     Pune\n",
      "87           88   19   Male  1st Class      yes  96.0     Pune\n",
      "92           93   20   Male  2nd Class      yes  74.0    Kochi\n",
      "94           95   21   Male  3rd Class      yes  50.0   Bhopal\n",
      "99          100   19   Male  1st Class      yes  84.0    Kochi\n",
      "101         102   19   Male  1st Class      yes  98.0  Chennai\n",
      "103         104   20   Male  2nd Class      yes  78.0   Mumbai\n",
      "105         106   21   Male  2nd Class      yes  77.0    Kochi\n",
      "116         117   19   Male  1st Class      yes  90.0    Kochi\n",
      "121         122   20   Male  2nd Class      yes  75.0   Mumbai\n",
      "123         124   21   Male  3rd Class      yes  49.0  Chennai\n",
      "128         129   19   Male  1st Class      yes  89.0  Gwalior\n",
      "130         131   19   Male  1st Class      yes  90.0  Chennai\n",
      "132         133   20   Male  2nd Class      yes  75.0   Mumbai\n",
      "134         135   21   Male  2nd Class      yes  75.0    Kochi\n",
      "145         146   19   Male  1st Class      yes  98.0   Mumbai\n",
      "150         151   20   Male  2nd Class      yes  78.0     Pune\n",
      "152         153   21   Male  3rd Class      yes  46.0  Gwalior\n",
      "157         158   19   Male  1st Class      yes  92.0     Pune\n",
      "159         160   19   Male  1st Class      yes  92.0    Delhi\n",
      "161         162   20   Male  2nd Class      yes  79.0     Pune\n",
      "163         164   21   Male  2nd Class      yes  75.0  Gwalior\n",
      "174         175   19   Male  1st Class      yes  84.0     Pune\n",
      "179         180   20   Male  2nd Class      yes  76.0    Delhi\n",
      "181         182   21   Male  3rd Class      yes  58.0     Pune\n",
      "186         187   19   Male  1st Class      yes  83.0    Kochi\n",
      "188         189   19   Male  1st Class      yes  89.0   Bhopal\n",
      "190         191   20   Male  2nd Class      yes  77.0    Delhi\n",
      "192         193   21   Male  2nd Class      yes  75.0     Pune\n",
      "203         204   19   Male  1st Class      yes  91.0     Pune\n",
      "208         209   20   Male  2nd Class      yes  70.0   Mumbai\n",
      "210         211   21   Male  3rd Class      yes  58.0    Kochi\n",
      "215         216   19   Male  1st Class      yes  95.0   Mumbai\n",
      "217         218   19   Male  1st Class      yes  96.0    Kochi\n",
      "219         220   20   Male  2nd Class      yes  75.0   Bhopal\n",
      "221         222   21   Male  2nd Class      yes  74.0    Kochi\n",
      "229         230   20   Male  3rd Class      yes  55.0    Delhi\n",
      "231         232   20   Male  3rd Class      yes  59.0     Pune\n"
     ]
    }
   ],
   "source": [
    "males_employed = combined_df[(combined_df['Gender'] == 'Male') & (combined_df['Employed'] == 'yes')]\n",
    "print(males_employed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cef4d-fb17-4518-a78d-dbdb495ab7f4",
   "metadata": {},
   "source": [
    "**e)\tCreate a new Column ‘IQ_level’ which will have 3 values (Intelligent, Mediocre, weak). If student scored more than 80 then Tag him as Intelligent, if student scored between 50-80, then Mediocre, else weak.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5a5cdc1f-5bbe-4730-a54a-91ad65527b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Student_id  Mark     IQ_level\n",
      "0             1  95.0  Intelligent\n",
      "1             2  70.0     Mediocre\n",
      "2             3  98.0  Intelligent\n",
      "3             4  75.0     Mediocre\n",
      "4             5  89.0  Intelligent\n",
      "..          ...   ...          ...\n",
      "227         228  99.0  Intelligent\n",
      "228         229  70.0     Mediocre\n",
      "229         230  55.0     Mediocre\n",
      "230         231  97.0  Intelligent\n",
      "231         232  59.0     Mediocre\n",
      "\n",
      "[232 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_df['IQ_level'] = np.where(combined_df['Mark'] > 80, 'Intelligent',\n",
    "                                    np.where(combined_df['Mark'] >= 50, 'Mediocre', 'Weak'))\n",
    "print(combined_df[['Student_id', 'Mark', 'IQ_level']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b524266-853c-41c3-840b-b32cc1e4be47",
   "metadata": {},
   "source": [
    "**f)\tCount the number of males and females from each city.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "187f6364-eca0-46be-9978-13ed6db6c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender   Female  Male\n",
      "City                 \n",
      "Bhopal       13    15\n",
      "Chennai      15    18\n",
      "Delhi        12    20\n",
      "Gwalior      14    18\n",
      "Kochi        10    21\n",
      "Mumbai       16    16\n",
      "Pune         15    26\n"
     ]
    }
   ],
   "source": [
    "gender_city_count = combined_df.groupby(['City', 'Gender']).size().unstack(fill_value=0)\n",
    "print(gender_city_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0aaaf-cf0d-4398-9ba4-de756f8953da",
   "metadata": {},
   "source": [
    "**g)\tPrint the top 5 Male scorers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "77f95bff-377f-4fc6-b245-6e55527171cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Student_id   Mark\n",
      "149         150  100.0\n",
      "147         148   99.0\n",
      "60           61   98.0\n",
      "62           63   98.0\n",
      "101         102   98.0\n"
     ]
    }
   ],
   "source": [
    "top_male_scorers = combined_df[combined_df['Gender'] == 'Male'].sort_values(by='Mark', ascending=False).head(5)\n",
    "print(top_male_scorers[['Student_id', 'Mark']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf6f8a-8c9e-4adb-ac95-9f319e285ddb",
   "metadata": {},
   "source": [
    "**h)\tReplace the Male value with M and Female value with F and export this dataframe to excel file in D: (D drive) and name the file as test.csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fbcef179-8ee9-435b-93c1-9bbb059b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Gender'] = combined_df['Gender'].replace({'Male': 'M', 'Female': 'F'})\n",
    "combined_df.to_csv('C:/Users/Under/Downloads/test.csv', index=False) #EXPORTING TO C DRIVE SINCE SYSTEM DOESNT HAVE A D DRIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7123ac-3635-497a-8237-63c448fa975f",
   "metadata": {},
   "source": [
    "**i)\tCheck if any student_ID is duplicated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "86a56f9c-2f1b-4525-902a-1af61c75648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Student_id, Age, Gender, Grade, Employed, Mark, City, IQ_level]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicated_students = combined_df[combined_df.duplicated(subset='Student_id', keep=False)]\n",
    "print(duplicated_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f7f06-6f8d-4f08-9c3c-07d6c9981bc6",
   "metadata": {},
   "source": [
    "**j)\tCreate a separate dataframe which will have all the Integer/Float variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f98b884c-55ae-42ff-8776-d14f3706aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Student_id  Age  Mark\n",
      "0             1   19  95.0\n",
      "1             2   20  70.0\n",
      "2             3   18  98.0\n",
      "3             4   21  75.0\n",
      "4             5   19  89.0\n",
      "..          ...  ...   ...\n",
      "227         228   21  99.0\n",
      "228         229   20  70.0\n",
      "229         230   20  55.0\n",
      "230         231   19  97.0\n",
      "231         232   20  59.0\n",
      "\n",
      "[232 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "numeric_df = combined_df.select_dtypes(include=['int64', 'float64'])\n",
    "print(numeric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0dbb2-4ec6-4fbb-9950-1d52cbbd8b2a",
   "metadata": {},
   "source": [
    "**k)\tGet those Student_IDs which are present in Students table but not in Marks table.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "620147e2-51b8-47af-b798-1276c620f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      9\n",
      "9     10\n",
      "48    49\n",
      "Name: Student_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_students = pd.merge(student_df, marks_df, on='Student_id', how='left', indicator=True)\n",
    "missing_students = unique_students[unique_students['_merge'] == 'left_only']['Student_id']\n",
    "print(missing_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660140f-bf10-434b-a12d-8e87993ed8c0",
   "metadata": {},
   "source": [
    "**3.Explain the concept of missing values. How can you identify the missing values in a Pandas DataFrame ?\n",
    "What are the different ways of treating/Imputing/Deleting the missing values.\n",
    "Explain with example.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910fa8a-fa22-49fa-8f06-de106a636b83",
   "metadata": {},
   "source": [
    "Missing values occur when data is absent for a particular observation (row) or feature (column) in a dataset. In a Pandas DataFrame, missing values are often represented by NaN (Not a Number) or None.\n",
    "Missing data can arise for various reasons:\n",
    "   Errors in data collection (e.g., missing responses in a survey),\n",
    "   incomplete data entry (e.g., fields left blank in a form),\n",
    "   data merging or joining issues when combining multiple datasets,\n",
    "   identifying missing values in a Pandas DataFrame,\n",
    "   \n",
    "Pandas provides several methods to identify missing values:\n",
    "\n",
    "**1. isna() and isnull()** Methods\n",
    "Both methods return a boolean DataFrame of the same shape as the original, where True indicates the presence of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "55bfbab8-0397-442e-a89d-bfdae7e03031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B      C\n",
      "0  False   True  False\n",
      "1  False  False   True\n",
      "2   True  False  False\n",
      "3  False  False  False\n"
     ]
    }
   ],
   "source": [
    "data = {'A': [1, 2, None, 4], \n",
    "        'B': [None, 2, 3, 4], \n",
    "        'C': [1, None, 3, 4]}\n",
    "df2 = pd.DataFrame(data)\n",
    "missing = df2.isna()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7574e-d8a7-481c-8156-7369b744549a",
   "metadata": {},
   "source": [
    "**2. sum() Method to Count Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7a462e2e-48d6-4179-8478-102bc734d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    1\n",
      "B    1\n",
      "C    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_count = df2.isna().sum()\n",
    "print(missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2cd56-65a7-4de6-9721-36712121e184",
   "metadata": {},
   "source": [
    "**3. info() Method:**\n",
    "The info() method provides a summary of the DataFrame, including the number of non-null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f5dd8916-aec1-4751-89b2-6ae2dea8173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       3 non-null      float64\n",
      " 1   B       3 non-null      float64\n",
      " 2   C       3 non-null      float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 228.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18743e0-b1f7-4c8b-88a1-a59544432d6f",
   "metadata": {},
   "source": [
    "There are several strategies to handle missing data, and the best approach depends on the nature of the data and the problem you're trying to solve.\n",
    "\n",
    "**1. Imputation (Filling Missing Values):**\n",
    "Imputation involves filling the missing values with meaningful replacements, such as using the mean, median, mode, or other statistical values, or even more advanced techniques like predictive imputation.\n",
    "\n",
    "**a) Filling with a constant value:**\n",
    "    We can replace missing values with a fixed value (e.g., 0, -1, or any other constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1eb9c818-566c-41f7-93bd-44785fb81d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  0.0  1.0\n",
      "1  2.0  2.0  0.0\n",
      "2  0.0  3.0  3.0\n",
      "3  4.0  4.0  4.0\n"
     ]
    }
   ],
   "source": [
    "df_filled = df2.fillna(0)  # Fill all NaNs with 0\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3aa964-9061-43e2-b08b-c48028e18d03",
   "metadata": {},
   "source": [
    "   **b) Filling with the mean, median, or mode:**\n",
    "    Mean imputation is often used for numerical columns,\n",
    "    Median imputation can be used for skewed distributions,\n",
    "    Mode imputation can be used for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "116197bb-9572-4879-bbaf-64156a1329fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A    B    C\n",
      "0  1.000000  NaN  1.0\n",
      "1  2.000000  2.0  NaN\n",
      "2  2.333333  3.0  3.0\n",
      "3  4.000000  4.0  4.0\n"
     ]
    }
   ],
   "source": [
    "df2['A'] = df2['A'].fillna(df2['A'].mean())  # Fill NaNs in column A with mean of A\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93b9bb-ccd4-443f-802d-63d2afa379f0",
   "metadata": {},
   "source": [
    "   **c) Forward Fill and Backward Fill:**\n",
    "    These methods fill the missing values by using the previous or next non-missing value in the column.\n",
    "\n",
    "    Forward fill (ffill) replaces missing values with the value from the previous row.\n",
    "    Backward fill (bfill) replaces missing values with the value from the next row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "df7f0104-ddbe-4ad6-92d7-d6dab8e3f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A    B    C\n",
      "0  1.000000  NaN  1.0\n",
      "1  2.000000  2.0  1.0\n",
      "2  2.333333  3.0  3.0\n",
      "3  4.000000  4.0  4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\under\\AppData\\Local\\Temp\\ipykernel_3456\\2323399587.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled_ffill = df2.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df_filled_ffill = df2.fillna(method='ffill')\n",
    "print(df_filled_ffill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf41002-dd42-45ed-9bd0-a22eee1128cb",
   "metadata": {},
   "source": [
    "**2. Dropping Missing Values (Deletion):**\n",
    "Sometimes, it is better to remove rows or columns with missing values rather than impute them, especially when the missing data is a small proportion of the entire dataset.\n",
    "\n",
    " **a) Drop rows with missing values:**\n",
    "     We can remove any row that contains at least one missing value using dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "671bd12e-de92-43f0-9ce6-ca6fdf5e5353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A    B    C\n",
      "2  2.333333  3.0  3.0\n",
      "3  4.000000  4.0  4.0\n"
     ]
    }
   ],
   "source": [
    "df_dropped_rows = df2.dropna()  # Drop any rows with NaN values\n",
    "print(df_dropped_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3214a4-3e7b-4900-b0ac-1b07dcc807e4",
   "metadata": {},
   "source": [
    "   **b) Drop columns with missing values:**\n",
    "    If a column contains too many missing values and you don't want to impute, you can drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e0f0c0cc-d5e3-4cb7-bca7-90a8118dae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A\n",
      "0  1.000000\n",
      "1  2.000000\n",
      "2  2.333333\n",
      "3  4.000000\n"
     ]
    }
   ],
   "source": [
    "df_dropped_columns = df2.dropna(axis=1)  # Drop columns with NaN values\n",
    "print(df_dropped_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d8190-18ce-4830-9e71-9e65e6d6104d",
   "metadata": {},
   "source": [
    "The choice of method depends on the dataset and the amount of missing data. Imputation is preferred when a lot of data is missing, and deletion is useful when only a small portion of the data is missing or if the missing values are unimportant for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d94973-bde4-44b3-b37f-5ed7b6b36d59",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
